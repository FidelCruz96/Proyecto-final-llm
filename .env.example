# =========================
# Router (Cloud Run)
# =========================

# URL pública del classifier (en Cloud Run)
# Debe incluir /predict al final (o ajusta en el código).
CLASSIFIER_URL=https://llm-classifier-911161541488.us-central1.run.app/predict

# Gemini API key (NO poner aquí en producción)
# En Cloud Run: inyectar desde Secret Manager (GEMINI_API_KEY)
GEMINI_API_KEY=

# Gemini settings
MAX_OUTPUT_TOKENS=1024
TEMPERATURE=0.2

# Server settings
PORT=8080
WEB_CONCURRENCY=1

# Optional: enable JSON logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Optional: tier → model mapping (si lo quieres configurable)
MODEL_SIMPLE=gemini-2.0-flash-lite
MODEL_MEDIUM=gemini-2.5-flash
MODEL_COMPLEX=gemini-1.5-pro

# =========================
# Classifier (Cloud Run)
# =========================

# Rule thresholds (optional)
SIMPLE_MAX=40
MEDIUM_MAX=120

# Optional: force tier for experiments (handled via request metadata)
# metadata.force_tier = simple|medium|complex
