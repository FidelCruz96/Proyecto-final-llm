version: "3.9"

services:
  classifier:
    build:
      context: ./classifier
    container_name: llm-classifier
    ports:
      - "8081:8080"
    environment:
      - PYTHONUNBUFFERED=1
    restart: unless-stopped

  router:
    build:
      context: ./router
    container_name: llm-router
    ports:
      - "8080:8080"
    environment:
      - CLASSIFIER_URL=http://classifier:8080/predict
      - PYTHONUNBUFFERED=1
    depends_on:
      - classifier
    restart: unless-stopped
